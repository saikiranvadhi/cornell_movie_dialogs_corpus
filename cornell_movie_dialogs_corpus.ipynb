{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run below when reading data from gdrive location or from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "NfY3ANY4stFZ",
    "outputId": "30335a7a-b85c-4deb-9752-b456f34b4458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "root_dir = \"/content/gdrive/My Drive/workspaces/\"\n",
    "base_dir = root_dir + 'data/'\n",
    "\n",
    "kaggle_json = root_dir + 'kaggle.json'\n",
    "\n",
    "! mkdir -p ~/.kaggle/\n",
    "! cp \"$kaggle_json\" ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "nJrEsKM1t6F-",
    "outputId": "24b24462-9334-4b2a-e4ed-77fc0269ea8a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 41M\n",
      "-rw------- 1 root root 284K May  7 14:51 chameleons.pdf\n",
      "-rw------- 1 root root 690K May  7 14:51 movie_characters_metadata.txt\n",
      "-rw------- 1 root root 4.1K May  7 14:51 README.txt\n",
      "-rw------- 1 root root  55K May  7 14:51 raw_script_urls.txt\n",
      "-rw------- 1 root root  66K May  7 14:51 movie_titles_metadata.txt\n",
      "-rw------- 1 root root 6.5M May  7 14:51 movie_conversations.txt\n",
      "-rw------- 1 root root  34M May  7 14:52 movie_lines.txt\n"
     ]
    }
   ],
   "source": [
    "# data url: http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
    "! ls -ltrh \"{base_dir}cornell_movie_dialogs_corpus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "SIp8FGlJs0Ra",
    "outputId": "53e11acf-5c71-4539-8e17-db84992b1832"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VDcD-_5FslMB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "QQOGsoEFslMM"
   },
   "outputs": [],
   "source": [
    "# Read files\n",
    "with open(base_dir + \"cornell_movie_dialogs_corpus/movie_conversations.txt\", 'r', encoding=\"latin1\") as conv_file:\n",
    "    conv_raw = pd.read_csv(conv_file, sep=\" \\+\\+\\+\\$\\+\\+\\+ \", header = None, engine = 'python')\n",
    "    conv_raw.columns = ['person1', 'person2', 'movie', 'conv_seq']\n",
    "\n",
    "with open(base_dir + \"cornell_movie_dialogs_corpus/movie_lines.txt\", 'r', encoding=\"latin1\") as conv_file:\n",
    "    conv_lines = pd.read_csv(conv_file, sep=\" \\+\\+\\+\\$\\+\\+\\+ \", header = None, engine = 'python')\n",
    "    conv_lines.columns = ['line_num', 'person', 'movie', 'person_name', 'dialog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read files\n",
    "with open(\"//QATLPCFS001/Users/skiran/Downloads/cornell_movie_dialogs_corpus/movie_conversations.txt\", 'r') as conv_file:\n",
    "    conv_raw = pd.read_csv(conv_file, sep=\" \\+\\+\\+\\$\\+\\+\\+ \", header = None, engine = 'python')\n",
    "    conv_raw.columns = ['person1', 'person2', 'movie', 'conv_seq']\n",
    "\n",
    "with open(\"//QATLPCFS001/Users/skiran/Downloads/cornell_movie_dialogs_corpus/movie_lines.txt\", 'r') as conv_file:\n",
    "    conv_lines = pd.read_csv(conv_file, sep=\" \\+\\+\\+\\$\\+\\+\\+ \", header = None, engine = 'python')\n",
    "    conv_lines.columns = ['line_num', 'person', 'movie', 'person_name', 'dialog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "JUHo2W-jslMU",
    "outputId": "ae268f1e-a9d5-4746-b592-e0ae6b79f62b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_num</th>\n",
       "      <th>person</th>\n",
       "      <th>movie</th>\n",
       "      <th>person_name</th>\n",
       "      <th>dialog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  line_num person movie person_name        dialog\n",
       "0    L1045     u0    m0      BIANCA  They do not!\n",
       "1    L1044     u2    m0     CAMERON   They do to!\n",
       "2     L985     u0    m0      BIANCA    I hope so.\n",
       "3     L984     u2    m0     CAMERON     She okay?\n",
       "4     L925     u0    m0      BIANCA     Let's go."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_lines.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Looks like some error reading few lines of conv_lines dataset\n",
    "# fixing it here\n",
    "print(sum(conv_lines.dialog.map(lambda x: x is None)))\n",
    "dialog_none = conv_lines['dialog'].isnull()\n",
    "conv_lines.loc[dialog_none, 'person_name'] = conv_lines.loc[dialog_none, 'person_name'].map(lambda x: x.replace(' +++$+++', ''))\n",
    "conv_lines.dialog.fillna(value=\"\", inplace=True)\n",
    "print(sum(conv_lines.dialog.map(lambda x: x is None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "jpWIgAgvslMQ",
    "outputId": "9ea5d138-aba1-47c6-999d-0ef14ec7a096"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person1</th>\n",
       "      <th>person2</th>\n",
       "      <th>movie</th>\n",
       "      <th>conv_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L194', 'L195', 'L196', 'L197']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L198', 'L199']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L200', 'L201', 'L202', 'L203']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L204', 'L205', 'L206']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>['L207', 'L208']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  person1 person2 movie                          conv_seq\n",
       "0      u0      u2    m0  ['L194', 'L195', 'L196', 'L197']\n",
       "1      u0      u2    m0                  ['L198', 'L199']\n",
       "2      u0      u2    m0  ['L200', 'L201', 'L202', 'L203']\n",
       "3      u0      u2    m0          ['L204', 'L205', 'L206']\n",
       "4      u0      u2    m0                  ['L207', 'L208']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VNh7DHhzslMX"
   },
   "outputs": [],
   "source": [
    "# Let's work on conv_raw\n",
    "# the 'conv_seq' column is in the form of a array, let's use it\n",
    "# and also add couple of columns for first and last lines in the dialog\n",
    "from ast import literal_eval\n",
    "conv_raw['conv_seq'] = conv_raw['conv_seq'].apply(lambda x: [line.replace('L', '') for line in literal_eval(x)])\n",
    "conv_raw['first_line'] = conv_raw['conv_seq'].apply(lambda x: x[0])\n",
    "conv_raw['last_line'] = conv_raw['conv_seq'].apply(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "I5Z3aba3slMa",
    "outputId": "5370a427-57cb-463d-bda7-76e7775a6aa8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person1</th>\n",
       "      <th>person2</th>\n",
       "      <th>movie</th>\n",
       "      <th>conv_seq</th>\n",
       "      <th>first_line</th>\n",
       "      <th>last_line</th>\n",
       "      <th>unique_ppm</th>\n",
       "      <th>unique_row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[194, 195, 196, 197]</td>\n",
       "      <td>194</td>\n",
       "      <td>197</td>\n",
       "      <td>u0u2m0</td>\n",
       "      <td>u0u2m0_197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[198, 199]</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>u0u2m0</td>\n",
       "      <td>u0u2m0_199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[200, 201, 202, 203]</td>\n",
       "      <td>200</td>\n",
       "      <td>203</td>\n",
       "      <td>u0u2m0</td>\n",
       "      <td>u0u2m0_203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[204, 205, 206]</td>\n",
       "      <td>204</td>\n",
       "      <td>206</td>\n",
       "      <td>u0u2m0</td>\n",
       "      <td>u0u2m0_206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[207, 208]</td>\n",
       "      <td>207</td>\n",
       "      <td>208</td>\n",
       "      <td>u0u2m0</td>\n",
       "      <td>u0u2m0_208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[271, 272, 273, 274, 275]</td>\n",
       "      <td>271</td>\n",
       "      <td>275</td>\n",
       "      <td>u0u2m0</td>\n",
       "      <td>u0u2m0_275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[276, 277]</td>\n",
       "      <td>276</td>\n",
       "      <td>277</td>\n",
       "      <td>u0u2m0</td>\n",
       "      <td>u0u2m0_277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[280, 281]</td>\n",
       "      <td>280</td>\n",
       "      <td>281</td>\n",
       "      <td>u0u2m0</td>\n",
       "      <td>u0u2m0_281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[363, 364]</td>\n",
       "      <td>363</td>\n",
       "      <td>364</td>\n",
       "      <td>u0u2m0</td>\n",
       "      <td>u0u2m0_364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>u0</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>[365, 366]</td>\n",
       "      <td>365</td>\n",
       "      <td>366</td>\n",
       "      <td>u0u2m0</td>\n",
       "      <td>u0u2m0_366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  person1 person2 movie                   conv_seq first_line last_line  \\\n",
       "0      u0      u2    m0       [194, 195, 196, 197]        194       197   \n",
       "1      u0      u2    m0                 [198, 199]        198       199   \n",
       "2      u0      u2    m0       [200, 201, 202, 203]        200       203   \n",
       "3      u0      u2    m0            [204, 205, 206]        204       206   \n",
       "4      u0      u2    m0                 [207, 208]        207       208   \n",
       "5      u0      u2    m0  [271, 272, 273, 274, 275]        271       275   \n",
       "6      u0      u2    m0                 [276, 277]        276       277   \n",
       "7      u0      u2    m0                 [280, 281]        280       281   \n",
       "8      u0      u2    m0                 [363, 364]        363       364   \n",
       "9      u0      u2    m0                 [365, 366]        365       366   \n",
       "\n",
       "  unique_ppm unique_row_id  \n",
       "0     u0u2m0    u0u2m0_197  \n",
       "1     u0u2m0    u0u2m0_199  \n",
       "2     u0u2m0    u0u2m0_203  \n",
       "3     u0u2m0    u0u2m0_206  \n",
       "4     u0u2m0    u0u2m0_208  \n",
       "5     u0u2m0    u0u2m0_275  \n",
       "6     u0u2m0    u0u2m0_277  \n",
       "7     u0u2m0    u0u2m0_281  \n",
       "8     u0u2m0    u0u2m0_364  \n",
       "9     u0u2m0    u0u2m0_366  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's add a few more columns similar to index\n",
    "conv_raw.sort_values(by = ['movie', 'person1', 'person2', 'first_line']).reset_index(drop = True)\n",
    "conv_raw['unique_ppm'] = conv_raw['person1'] + conv_raw['person2'] + conv_raw['movie']\n",
    "conv_raw['unique_row_id'] = conv_raw['unique_ppm'] + \"_\" + conv_raw['last_line']\n",
    "conv_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "a3Q8pk_fslMe"
   },
   "outputs": [],
   "source": [
    "# I'm trying to concatenate dialogues between the same two people\n",
    "# and if the dialogues are in succession but broken into different rows in the data\n",
    "g = (conv_raw['unique_ppm'] + \"_\" + (conv_raw['first_line'].map(int) - 1).map(str) != conv_raw.shift().fillna(method='bfill')['unique_row_id']).cumsum().rename('group')\n",
    "conv_agg = conv_raw.groupby(['person1', 'person2', 'movie', g])['conv_seq'].apply(list).reset_index().drop('group',axis=1)\n",
    "conv_agg['conv_seq'] = conv_agg['conv_seq'].apply(lambda l: [item for sublist in l for item in sublist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "AAdWtBTrslMk",
    "outputId": "e70aa1f4-5088-4174-cc63-a85f06581b63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  person1 person2 movie                                           conv_seq\n",
      "0      u0     u11    m0                          [179, 180, 181, 182, 183]\n",
      "1      u0     u11    m0                                         [189, 190]\n",
      "2      u0     u11    m0                          [517, 518, 519, 520, 521]\n",
      "3      u0     u11    m0                                         [523, 524]\n",
      "4      u0     u11    m0                          [536, 537, 538, 539, 540]\n",
      "5      u0     u11    m0                                    [544, 545, 546]\n",
      "6      u0     u11    m0                [878, 879, 880, 881, 882, 883, 884]\n",
      "7      u0     u11    m0                                         [922, 923]\n",
      "8      u0      u2    m0  [194, 195, 196, 197, 198, 199, 200, 201, 202, ...\n",
      "9      u0      u2    m0                [271, 272, 273, 274, 275, 276, 277]\n",
      "(83097, 8) (60699, 4)\n"
     ]
    }
   ],
   "source": [
    "print(conv_agg.head(10))\n",
    "print(conv_raw.shape, conv_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "T_btDLmXslMr"
   },
   "outputs": [],
   "source": [
    "# Creating a function to clean out the input sentences\n",
    "import re\n",
    "\n",
    "def clean_sentence(raw_sent):\n",
    "    raw_sent = raw_sent.lower()\n",
    "    # remove html tags like <i>, </u>\n",
    "    raw_sent = re.sub(r'<\\/*[a-z]?>', '', raw_sent)\n",
    "    raw_sent = re.sub(r'[<>]', '', raw_sent)\n",
    "    # special character for 'pause' (..., ---) replaced with \"<pause>\"\n",
    "    raw_sent = re.sub(r'\\s*(\\.\\.+|--+|…+)\\s*', ' <pause> ', raw_sent)\n",
    "    # - replaced with space\n",
    "    raw_sent = re.sub(r'-|—', ' ', raw_sent)\n",
    "    # remove double quotes\n",
    "    raw_sent = re.sub(r'\\\"', '', raw_sent)\n",
    "    # remove single quotes around words\n",
    "    raw_sent = re.sub(r'[‘’]', '\\'', raw_sent)\n",
    "    raw_sent = re.sub(r'\\'([a-z]+)\\'', r'\\1', raw_sent)\n",
    "    raw_sent = re.sub(r' \\'([a-z]+)\\b', r' \\1', raw_sent)\n",
    "    raw_sent = re.sub(r'( [a-z]+s\\') ', r'\\1s ', raw_sent)\n",
    "    # words like doin', goin' to be replaced with doing, going\n",
    "    raw_sent = re.sub(r'([a-z]+)in\\'', r'\\1ing', raw_sent)\n",
    "    # you've, there've replaced with you have, there have\n",
    "    raw_sent = re.sub(r'([a-z]+)\\'ve', r'\\1 have', raw_sent)\n",
    "    # we're replaced with we are\n",
    "    raw_sent = re.sub(r'([a-z]+)\\'re', r'\\1 are', raw_sent)\n",
    "    # treat commas and other EOS tags as words (put space around them)\n",
    "    raw_sent = re.sub(r'\\s*([\\.,!\\?]+)\\s*', r' \\1 ', raw_sent)\n",
    "    # 's to be seperated from the word with some exceptions\n",
    "    raw_sent = re.sub(r'([a-z]+)(\\'s)\\b', r'\\1 \\2 ', raw_sent)\n",
    "    exceptions = r\"\\b(it|that|there|he|she|let) (\\'s)\"\n",
    "    raw_sent = re.sub(exceptions, r'\\1\\2', raw_sent)\n",
    "    # remove leading and trailing spaces\n",
    "    raw_sent = re.sub(r'^\\s*|\\s*$', '', raw_sent)\n",
    "    raw_sent = re.sub(r'\\s+', ' ', raw_sent)\n",
    "    # add <eos> tag at the end of sentence\n",
    "    raw_sent = raw_sent + \" <eos>\"\n",
    "    return(raw_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "_ZibnomFslMn",
    "outputId": "5be7a38f-3d4d-402e-aaad-48a8dd23eb48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -Sai --Kiran---V's-123.. <a> Sai   \"you've been,   've doin' . somethin' but\" it 's ?everythin flat's ans' 'knows'  \n",
      "   -Sai --Kiran---V's-123.. <a> Sai   \"you've been,   've doin' . somethin' but\" it's ?everythin flat's ans' 'knows'  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"sai <pause> kiran <pause> v 's 123 <pause> sai you have been , ve doing . something but it s ? everythin flat 's ans 's knows <eos>\""
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just testing regex for clean_sentence function, delete this when done function building\n",
    "import re\n",
    "raw_sent = \"   -Sai --Kiran---V's-123.. <a> Sai   \\\"you've been,   've doin' . somethin' but\\\" it 's ?everythin flat's ans' 'knows'  \"\n",
    "print(raw_sent)\n",
    "exceptions = r\"\\b(it|that|there|he|she|let) (\\'s)\"\n",
    "print(re.sub(exceptions, r'\\1\\2', raw_sent))\n",
    "clean_sentence(raw_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "DIaboMeeslMv"
   },
   "outputs": [],
   "source": [
    "all_dialogs = conv_lines.dialog.map(clean_sentence).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sometimes i wonder if the guys we are supposed to want to go out with are the ones we actually want to go out with , you know ? <eos>'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dialogs[74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "3h73eKQ18pAw"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": false,
    "id": "4OPLwZTiQSOm",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeah , he's your freak friend mandella 's boyfriend . i guess since i'm not allowed to go out , i should obsess over a dead guy , too . <eos>\n",
      "[[79, 3, 84, 30, 1882, 283, 26185, 28, 1162, 1, 5, 222, 327, 27, 35, 1683, 8, 63, 48, 3, 5, 137, 39694, 122, 10, 215, 170, 3, 110, 1, 2]]\n",
      "[[79, 3, 84, 30, 1882, 283, 26185, 28, 1162, 1, 5, 222, 327, 27, 35, 1683, 8, 63, 48, 3, 5, 137, 122, 10, 215, 170, 3, 110, 1, 2]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode text\n",
    "tokenizer = Tokenizer(filters='#$%&()*+-/:;=@[\\\\]^_`{|}~\\t\\n“')\n",
    "tokenizer.fit_on_texts(all_dialogs)\n",
    "\n",
    "print(all_dialogs[144])\n",
    "print(tokenizer.texts_to_sequences([all_dialogs[144]]))\n",
    "\n",
    "# Removing words with frequency less than a threshold\n",
    "count_thres = 2\n",
    "low_count_words = [w for w,c in tokenizer.word_counts.items() if c < count_thres]\n",
    "for w in low_count_words:\n",
    "    del tokenizer.word_index[w]\n",
    "    del tokenizer.word_docs[w]\n",
    "    del tokenizer.word_counts[w]\n",
    "\n",
    "print(tokenizer.texts_to_sequences([all_dialogs[144]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19297"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(low_count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31000"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sometimes i wonder if the guys we are supposed to want to go out with are the ones we actually want to go out with , you know ? <eos>\n",
      "[485, 4, 719, 48, 6, 275, 21, 13, 387, 7, 54, 7, 62, 47, 39, 13, 6, 776, 21, 419, 54, 7, 62, 47, 39, 3, 27, 5, 2]\n"
     ]
    }
   ],
   "source": [
    "print(all_dialogs[74])\n",
    "encoded = tokenizer.texts_to_sequences(all_dialogs)\n",
    "print(encoded[74])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'consecrate': 1,\n",
       " 'stacy': 37,\n",
       " 'truckload': 3,\n",
       " 'puppetmaster': 1,\n",
       " 'parachutes': 3,\n",
       " 'outrunning': 2,\n",
       " 'ratings': 17,\n",
       " 'cappoli': 2,\n",
       " 'unite': 11,\n",
       " 'photographs': 42,\n",
       " 'cellulars': 1,\n",
       " 'twenty—four': 1,\n",
       " 'ronkonkoma': 1,\n",
       " 'campfire': 3,\n",
       " 'helms': 24,\n",
       " 'prussians': 1,\n",
       " 'honky': 5,\n",
       " 'rectum': 2,\n",
       " 'satchels': 1,\n",
       " 'grampa': 16,\n",
       " 'gravedigger': 1,\n",
       " 'marshal': 28,\n",
       " 'exercised': 4,\n",
       " 'pyjamas': 4,\n",
       " 'guards': 80,\n",
       " 'myself—this': 1,\n",
       " 'hennessy': 3,\n",
       " 'geniuses': 7,\n",
       " 'computer': 242,\n",
       " 'barrymore': 1,\n",
       " 'waking': 34,\n",
       " 'stomping': 4,\n",
       " \"'ay\": 1,\n",
       " 'lednov': 14,\n",
       " 'erica': 26,\n",
       " 'doug': 71,\n",
       " 'tuaregs': 1,\n",
       " \"'conquering\": 1,\n",
       " 'programmed': 34,\n",
       " 'herb': 20,\n",
       " '‘that': 1,\n",
       " 'jockeying': 1,\n",
       " 'ulundi': 2,\n",
       " 'vowed': 5,\n",
       " 'thee': 76,\n",
       " 'martinsburg': 1,\n",
       " 'summaries': 1,\n",
       " 'cabbageville': 1,\n",
       " 'louella': 8,\n",
       " 'nuys': 3,\n",
       " 'crust': 5,\n",
       " 'syrah': 1,\n",
       " 'colosseum': 8,\n",
       " 'marylinize': 1,\n",
       " 'hel1': 1,\n",
       " 'arastrado': 1,\n",
       " 'aurore': 1,\n",
       " 'presidential': 15,\n",
       " 'valuing': 2,\n",
       " 'unprincipled': 1,\n",
       " \"people'll\": 4,\n",
       " 'vail': 1,\n",
       " 'fro': 6,\n",
       " 'tablets': 2,\n",
       " 'emptied': 11,\n",
       " '85': 10,\n",
       " 'hallucinations': 12,\n",
       " 'paco': 4,\n",
       " 'harbor': 44,\n",
       " '17th': 5,\n",
       " 'beck': 12,\n",
       " 'uses': 48,\n",
       " '1138': 1,\n",
       " 'cloudcuckooland': 1,\n",
       " 'guy—': 1,\n",
       " 'quantities': 2,\n",
       " 'ona': 1,\n",
       " 'sports': 48,\n",
       " 'tudor': 2,\n",
       " 'commandeered': 1,\n",
       " 'bombing': 18,\n",
       " 'astounding': 4,\n",
       " 'damndest': 4,\n",
       " 'silver': 81,\n",
       " 'geneva': 19,\n",
       " 'pounders': 1,\n",
       " 'regrettable': 4,\n",
       " 'monsieur': 98,\n",
       " 'extricate': 1,\n",
       " 'utter': 11,\n",
       " 'whoring': 1,\n",
       " 'impure': 2,\n",
       " 'caseworker': 1,\n",
       " 'pixilated': 8,\n",
       " 'ben': 321,\n",
       " 'extradite': 2,\n",
       " 'elevators': 9,\n",
       " 'salieri': 11,\n",
       " 'couer': 13,\n",
       " 'answer': 650,\n",
       " 'baaaa': 2,\n",
       " 'afoot': 3,\n",
       " \"m'i\": 2,\n",
       " 'paperbacks': 2,\n",
       " 'millenium': 1,\n",
       " 'goldman': 1,\n",
       " 'quintus': 5,\n",
       " 'gaston': 21,\n",
       " 'dissertation': 6,\n",
       " 'repeated': 9,\n",
       " 'shoplifters': 1,\n",
       " 'ecstasy': 6,\n",
       " 'experiment': 59,\n",
       " 'silvana': 1,\n",
       " 'wanders': 7,\n",
       " 'martineau': 2,\n",
       " 'dunn': 8,\n",
       " 'aaauuuhhh': 1,\n",
       " 'flat’s': 1,\n",
       " \"shouldn'ta\": 3,\n",
       " 'sbi': 1,\n",
       " 'infrastructure': 5,\n",
       " 'emulate': 2,\n",
       " 'celebrity': 26,\n",
       " 'get—': 2,\n",
       " 'royces': 1,\n",
       " 'consummated': 1,\n",
       " 'scrubbers': 2,\n",
       " 'sparked': 1,\n",
       " 'primaries': 1,\n",
       " 'sofie': 7,\n",
       " 'stretching': 6,\n",
       " 'handloads': 1,\n",
       " 'dillard': 1,\n",
       " 'motivate': 2,\n",
       " 'coleslaw': 1,\n",
       " 'famous': 154,\n",
       " 'fasil': 3,\n",
       " 'dodgy': 2,\n",
       " 'maggot': 2,\n",
       " 'trinket': 3,\n",
       " 'sight': 125,\n",
       " 'sill': 3,\n",
       " 'apples': 38,\n",
       " 'suggesting': 35,\n",
       " 'liberalism': 3,\n",
       " 'entreat': 2,\n",
       " \"he'd\": 440,\n",
       " 'pari': 4,\n",
       " \"i'a\": 1,\n",
       " 'privileged': 10,\n",
       " 'overriding': 1,\n",
       " 'hiccup': 2,\n",
       " 'junket': 1,\n",
       " 'ditzy': 1,\n",
       " \"service'll\": 1,\n",
       " 'xes': 1,\n",
       " 'drovers': 1,\n",
       " 'kurtzweil': 10,\n",
       " 'guissepe': 3,\n",
       " 'radios': 11,\n",
       " 'reconfiguration': 1,\n",
       " 'paleo': 1,\n",
       " 'morlock': 1,\n",
       " 'denied': 29,\n",
       " 'transport': 49,\n",
       " 'happens': 528,\n",
       " 'baggie': 3,\n",
       " 'rmprmmh': 1,\n",
       " '225': 1,\n",
       " 'waltzes': 1,\n",
       " 'shirelles': 1,\n",
       " 'freebasemaybe': 1,\n",
       " 'mccall': 11,\n",
       " 'villachaise': 1,\n",
       " 'accomodations': 1,\n",
       " 'hhhuh': 1,\n",
       " 'tomb': 31,\n",
       " 'inn': 49,\n",
       " 'isolationism': 1,\n",
       " 'vanden': 1,\n",
       " \"homes'\": 1,\n",
       " 'dons': 2,\n",
       " 'conjuction': 1,\n",
       " 'certainment': 1,\n",
       " 'yvonne': 8,\n",
       " 'scenario': 18,\n",
       " 'animatronics': 3,\n",
       " 'jiff': 1,\n",
       " 'catheter': 2,\n",
       " 'unpack': 7,\n",
       " 'jurgensen': 2,\n",
       " 'reprisal': 2,\n",
       " 'typed': 5,\n",
       " 'gigolo—or': 1,\n",
       " 'metropolitan': 9,\n",
       " 'mickeymouse': 1,\n",
       " 'muffet': 1,\n",
       " \"'90s\": 1,\n",
       " 'ich': 19,\n",
       " 'nazareth': 3,\n",
       " 'hereby': 14,\n",
       " 'human': 466,\n",
       " 'disappear': 98,\n",
       " 'frack': 2,\n",
       " 'tunnel': 77,\n",
       " 'excite': 4,\n",
       " 'trivia': 4,\n",
       " 'ooomph': 3,\n",
       " 'czar': 13,\n",
       " 'deceive': 14,\n",
       " \"'playboy\": 1,\n",
       " 'bismarck': 1,\n",
       " 'suppressant': 1,\n",
       " 'alriight': 1,\n",
       " 'blast': 54,\n",
       " 'caladan': 1,\n",
       " 'massacres': 3,\n",
       " 'fourty': 1,\n",
       " 'count': 271,\n",
       " 'facetious': 1,\n",
       " 'phosphorous': 3,\n",
       " 'strasser': 12,\n",
       " 'swastika': 3,\n",
       " 'feldwebel': 1,\n",
       " '364': 1,\n",
       " '500': 42,\n",
       " 'feelings': 191,\n",
       " 'archbishop': 6,\n",
       " 'swaps': 2,\n",
       " 'stuff—much': 1,\n",
       " 'hash': 13,\n",
       " 'contorted': 1,\n",
       " 'beginner': 3,\n",
       " 'encryption': 4,\n",
       " \"girlfriends'\": 1,\n",
       " 'stillsuits': 1,\n",
       " 'encore': 5,\n",
       " 'authenticated': 1,\n",
       " 'jesting': 1,\n",
       " \"didn't—\": 2,\n",
       " 'ove': 2,\n",
       " 'aufstehen': 1,\n",
       " 'élysées': 1,\n",
       " 'weedkiller': 1,\n",
       " 'whenna': 1,\n",
       " 'nunnery': 1,\n",
       " 'grind': 7,\n",
       " 'clarification': 1,\n",
       " 'selecting': 3,\n",
       " 'poletti': 1,\n",
       " 'diem': 11,\n",
       " 'suc': 1,\n",
       " 'madison': 32,\n",
       " 'activists': 1,\n",
       " \"aim'd\": 1,\n",
       " 'characteristic': 1,\n",
       " 'ried': 1,\n",
       " 'keyring': 1,\n",
       " 'elemental': 2,\n",
       " 'tilled': 1,\n",
       " 'book': 622,\n",
       " 'engraved': 7,\n",
       " 'heartening': 1,\n",
       " 'forget': 1047,\n",
       " 'ecologist': 1,\n",
       " 'stepmommy': 1,\n",
       " \"'tomorrow\": 1,\n",
       " 'cleanse': 2,\n",
       " 'decrepit': 2,\n",
       " 'moons': 5,\n",
       " 'rosie': 10,\n",
       " 'lowenthal': 3,\n",
       " 'findley': 6,\n",
       " 'tourelles': 6,\n",
       " 'omaha': 9,\n",
       " 'stabilizing': 2,\n",
       " 'amino': 1,\n",
       " 'sherlock': 6,\n",
       " 'patten': 6,\n",
       " 'katherina': 2,\n",
       " 'caputt': 1,\n",
       " 'mathematicians': 1,\n",
       " 'therapeutics': 1,\n",
       " 'slapped': 22,\n",
       " 'frowny': 1,\n",
       " 'sixy': 1,\n",
       " 'pit': 37,\n",
       " 'filler': 2,\n",
       " 'hag': 6,\n",
       " 'bootlegger': 6,\n",
       " 'kazansky': 1,\n",
       " 'abduct': 3,\n",
       " 'guess': 1950,\n",
       " 'adjustable': 1,\n",
       " 'versions': 5,\n",
       " 'barbecues': 2,\n",
       " 'potent': 6,\n",
       " 'brushed': 3,\n",
       " 'coonskin': 1,\n",
       " 'circle': 41,\n",
       " 'hikita': 3,\n",
       " 'utah': 38,\n",
       " 'vote': 80,\n",
       " 'four': 1224,\n",
       " 'fucks': 46,\n",
       " 'abbe': 16,\n",
       " \"radio'll\": 1,\n",
       " 'standoff': 1,\n",
       " 'plait': 2,\n",
       " 'invented': 56,\n",
       " 'sacha': 6,\n",
       " 'ratio': 6,\n",
       " 'undivided': 1,\n",
       " 'here': 13165,\n",
       " 'siwash': 9,\n",
       " 'identical': 19,\n",
       " 'salazar': 8,\n",
       " 'banished': 12,\n",
       " 'hanks': 1,\n",
       " 'ai': 3,\n",
       " 'okra': 6,\n",
       " 'slinky': 6,\n",
       " 'stickney': 1,\n",
       " 'bhagavad': 1,\n",
       " 'oplan': 1,\n",
       " 'inspiring': 11,\n",
       " 'stillwater': 2,\n",
       " 'midseason': 1,\n",
       " 'lations': 1,\n",
       " 'hindenberg': 1,\n",
       " \"dream'd\": 1,\n",
       " 'debt': 37,\n",
       " 'bellum': 1,\n",
       " 'duel': 6,\n",
       " 'dictate': 10,\n",
       " 'recondo': 1,\n",
       " 'polish': 39,\n",
       " 'doctore': 1,\n",
       " 'violinists': 1,\n",
       " 'junie': 2,\n",
       " \"is't\": 2,\n",
       " 'sinner': 6,\n",
       " 'femme': 2,\n",
       " 'of—': 1,\n",
       " 'scanning': 8,\n",
       " \"brat—i'm\": 1,\n",
       " 'edgars': 1,\n",
       " 'communicate': 31,\n",
       " \"'bid\": 1,\n",
       " 'francis': 43,\n",
       " 'schofield': 6,\n",
       " 'lable': 1,\n",
       " \"princess'\": 3,\n",
       " 'simultaneous': 3,\n",
       " 'bake': 13,\n",
       " 'untouched': 3,\n",
       " 'ode': 2,\n",
       " \"see—'\": 1,\n",
       " 'laundromats': 1,\n",
       " 'continuous': 4,\n",
       " 'annulment': 6,\n",
       " 'expediting': 3,\n",
       " 'ramses': 1,\n",
       " 'abundance': 2,\n",
       " 'vegan': 1,\n",
       " 'weasles': 2,\n",
       " 'okashii': 1,\n",
       " 'fingly': 1,\n",
       " 'pecan': 5,\n",
       " \"steve'll\": 1,\n",
       " 'freezing': 52,\n",
       " \"rays'\": 1,\n",
       " 'gully': 3,\n",
       " 'ignoble': 1,\n",
       " 'extraordinary': 42,\n",
       " 'alla': 15,\n",
       " 'lyndsey': 2,\n",
       " 'pipelines': 2,\n",
       " 'vaccinated': 1,\n",
       " 'stat': 6,\n",
       " 'havel': 3,\n",
       " 'psychoanalysis': 1,\n",
       " 'altamont': 1,\n",
       " 'pipkin': 1,\n",
       " 'survivalist': 2,\n",
       " 'ion': 6,\n",
       " 'ottos': 10,\n",
       " 'romper': 1,\n",
       " 'jennifer': 62,\n",
       " \"'civic\": 1,\n",
       " \"shouldn'a\": 1,\n",
       " 'graver': 2,\n",
       " 'neurologist': 3,\n",
       " 'chutney': 5,\n",
       " \"epps'\": 2,\n",
       " \"what'you\": 2,\n",
       " 'unhooked': 2,\n",
       " 'fibula': 1,\n",
       " 'carcel': 1,\n",
       " 'reverso': 1,\n",
       " 'covering': 38,\n",
       " 'diebold': 4,\n",
       " 'rectangle': 3,\n",
       " 'snowbank': 1,\n",
       " 'motor': 45,\n",
       " 'brimstones': 1,\n",
       " 'kompong': 1,\n",
       " 'macomber': 2,\n",
       " 'foreseeable': 2,\n",
       " 'stupider': 2,\n",
       " 'burying': 12,\n",
       " 'scotia': 1,\n",
       " 'sat': 100,\n",
       " 'appear—and': 1,\n",
       " 'underwire': 2,\n",
       " 'jekyll': 2,\n",
       " 'closed': 196,\n",
       " 'communicator': 6,\n",
       " 'retrieve': 10,\n",
       " 'hause': 2,\n",
       " 'chewing': 21,\n",
       " 'accidentally': 18,\n",
       " 'fondest': 1,\n",
       " 'loy': 1,\n",
       " 'nawyeckas': 1,\n",
       " 'killed': 1342,\n",
       " 'western': 61,\n",
       " 'unofficial': 5,\n",
       " 'mandatory': 7,\n",
       " 'jackpot': 8,\n",
       " 'oyo': 1,\n",
       " 'breakfast': 191,\n",
       " 'nasarei': 2,\n",
       " 'spaniard': 2,\n",
       " 'testicle': 2,\n",
       " 'suga': 7,\n",
       " 'dardis': 4,\n",
       " 'developed': 44,\n",
       " 'sodie': 1,\n",
       " 'testify': 56,\n",
       " 'madhouse': 6,\n",
       " 'forecourse': 2,\n",
       " 'jeffery': 1,\n",
       " 'persuasion': 4,\n",
       " 'automates': 1,\n",
       " 'hookus': 1,\n",
       " 'excavations': 1,\n",
       " 'guarded': 14,\n",
       " \"barracks'\": 1,\n",
       " 'typically': 10,\n",
       " 'exorbitant': 1,\n",
       " 'babysit': 4,\n",
       " \"p'seption\": 1,\n",
       " 'reptile': 4,\n",
       " 'entrusted': 8,\n",
       " 'decaying': 1,\n",
       " 'four—footed': 1,\n",
       " 'vouched': 8,\n",
       " \"job'll\": 1,\n",
       " 'captive': 6,\n",
       " 'seeding': 2,\n",
       " 'tottenham': 3,\n",
       " 'interruptions': 2,\n",
       " 'trusties': 1,\n",
       " 'durante': 1,\n",
       " 'pompous': 6,\n",
       " \"bleed'm\": 1,\n",
       " 'body': 649,\n",
       " 'topographic': 1,\n",
       " 'unpar': 1,\n",
       " 'inclination': 6,\n",
       " 'ferrie': 22,\n",
       " 'certain': 324,\n",
       " 'eww': 3,\n",
       " 'exchanges': 1,\n",
       " 'laller': 1,\n",
       " 'prescribed': 1,\n",
       " 'stumps': 4,\n",
       " 'timonioum': 1,\n",
       " 'amorgos': 1,\n",
       " '1942': 4,\n",
       " 'sometimes': 723,\n",
       " 'headway': 2,\n",
       " 'masculinity': 1,\n",
       " 'dalala': 1,\n",
       " 'kennison': 1,\n",
       " 'icers': 1,\n",
       " 'punters': 8,\n",
       " 'admired': 19,\n",
       " '50': 62,\n",
       " 'christendom': 2,\n",
       " 'gear': 81,\n",
       " 'skiddy': 1,\n",
       " 'crikey': 1,\n",
       " 'turbines': 2,\n",
       " 'yaddda': 1,\n",
       " 'serge': 2,\n",
       " 'afaid': 1,\n",
       " 'nexus': 20,\n",
       " 'sojef': 1,\n",
       " 'buffers': 1,\n",
       " 'dewitt': 15,\n",
       " 'phantom': 20,\n",
       " 'enormously': 6,\n",
       " 'gouge': 1,\n",
       " \"thousand'll\": 1,\n",
       " 'dealership': 4,\n",
       " 'coast': 88,\n",
       " 'teague': 1,\n",
       " \"j'etais\": 1,\n",
       " 'lasa': 1,\n",
       " 'sh—': 1,\n",
       " '130': 4,\n",
       " 'oxalate': 1,\n",
       " 'latour': 3,\n",
       " 'orlac': 5,\n",
       " '5151': 1,\n",
       " 'sigmoid': 1,\n",
       " 'tamed': 2,\n",
       " '7d': 1,\n",
       " 'episodic': 1,\n",
       " 'beeping': 1,\n",
       " 'platoon': 11,\n",
       " \"gotta'\": 1,\n",
       " 'tributaries': 1,\n",
       " 'racehorse': 2,\n",
       " 'froom': 1,\n",
       " 'nearest': 31,\n",
       " 'shinning': 1,\n",
       " 'puede': 1,\n",
       " 'cartographer': 1,\n",
       " 'temperatures': 5,\n",
       " 'ecosystem': 2,\n",
       " 'headline': 8,\n",
       " 'listen': 1861,\n",
       " 'confessed': 16,\n",
       " 'researchers': 2,\n",
       " 'guiding': 7,\n",
       " 'electra': 7,\n",
       " 'jism': 1,\n",
       " 'bonsoir': 2,\n",
       " 'cumma': 3,\n",
       " 'poontang': 1,\n",
       " 'lifter': 1,\n",
       " 'promethean': 1,\n",
       " 'corruption': 16,\n",
       " 'waldman': 6,\n",
       " 'interpretation': 10,\n",
       " 'disposed': 6,\n",
       " 'treads': 2,\n",
       " 'tippecanoe': 1,\n",
       " 'nullify': 1,\n",
       " 'tuck': 18,\n",
       " 'playhouse': 4,\n",
       " 'seam': 1,\n",
       " 'honorably': 1,\n",
       " 'lax': 11,\n",
       " 'looks—': 1,\n",
       " 'barbaric': 9,\n",
       " 'continue': 120,\n",
       " 'overcame': 1,\n",
       " 'doctored': 5,\n",
       " 'culled': 1,\n",
       " 'nicoli': 2,\n",
       " 'bookstores': 1,\n",
       " 'ulysses': 1,\n",
       " 'scuttles': 1,\n",
       " 'clutches': 3,\n",
       " 'anamaria': 2,\n",
       " 'eastern': 33,\n",
       " 'thruster': 3,\n",
       " 'section': 87,\n",
       " 'proletarian': 1,\n",
       " 'fame': 37,\n",
       " 'margaritaville': 1,\n",
       " 'rhinoceros': 3,\n",
       " 'impersonal': 8,\n",
       " \"look'\": 1,\n",
       " 'ntis': 2,\n",
       " 'although': 94,\n",
       " 'dig': 150,\n",
       " 'annie': 133,\n",
       " 'premiere': 11,\n",
       " 'tender': 23,\n",
       " 'batya': 1,\n",
       " 'john': 888,\n",
       " 'admittance': 10,\n",
       " 'demolitions': 4,\n",
       " 'drags': 6,\n",
       " 'poet': 44,\n",
       " 'rapunzel': 2,\n",
       " 'president—': 1,\n",
       " 'peary': 1,\n",
       " 'came—': 1,\n",
       " 'fiancé': 9,\n",
       " 'czars': 1,\n",
       " 'morey': 1,\n",
       " 'erogenous': 4,\n",
       " 'toys': 33,\n",
       " 'tallahassee': 3,\n",
       " 'pleasanter': 2,\n",
       " 'precogs': 17,\n",
       " 'clurman': 1,\n",
       " 'transference': 4,\n",
       " 'spawning': 1,\n",
       " 'surferings': 1,\n",
       " 'mops': 1,\n",
       " 'butchered': 12,\n",
       " 'arson': 11,\n",
       " \"lines'll\": 2,\n",
       " 'makings': 1,\n",
       " 'severing': 1,\n",
       " 'mayday': 3,\n",
       " \"202's\": 1,\n",
       " 'wineries': 1,\n",
       " 'previa': 1,\n",
       " 'nuclei': 1,\n",
       " 'falters': 1,\n",
       " 'extracurricular': 5,\n",
       " 'peyote': 2,\n",
       " 'eliminations': 1,\n",
       " 'monitoring': 11,\n",
       " 'hemorrhaging': 8,\n",
       " 'object': 81,\n",
       " 'roommates': 6,\n",
       " 'tulips': 1,\n",
       " 'nessie': 2,\n",
       " 'stormed': 4,\n",
       " 'evident—with': 1,\n",
       " 'bulletholes': 2,\n",
       " 'meccano': 2,\n",
       " 'lovemaking': 5,\n",
       " 'circumvent': 2,\n",
       " 'pluribus': 1,\n",
       " 'caulfield': 3,\n",
       " 'expand': 18,\n",
       " \"'knows\": 1,\n",
       " 'beauti': 1,\n",
       " 'ning': 1,\n",
       " 'friend': 1448,\n",
       " 'clockworks': 5,\n",
       " 'bening': 1,\n",
       " 'shylock': 7,\n",
       " 'grey': 39,\n",
       " 'pattica': 1,\n",
       " 'dragging': 39,\n",
       " 'duchamp': 1,\n",
       " 'blinker': 3,\n",
       " 'videographer': 1,\n",
       " 'feldmans': 2,\n",
       " 'sholes': 3,\n",
       " 'sequencer': 2,\n",
       " 'oppressive': 1,\n",
       " 'munching': 1,\n",
       " 'shomer': 1,\n",
       " 'squint': 3,\n",
       " 'daisy': 18,\n",
       " 'accounts': 43,\n",
       " 'asick': 1,\n",
       " 'symbols': 10,\n",
       " 'cars': 159,\n",
       " 'annina': 1,\n",
       " 'scorned': 2,\n",
       " 'joanne': 16,\n",
       " 'thump': 1,\n",
       " 'subspecies': 1,\n",
       " 'maping': 1,\n",
       " 'polytechnique': 1,\n",
       " 'ghastly': 11,\n",
       " 'fluent': 4,\n",
       " 'francs': 34,\n",
       " 'unforseen': 1,\n",
       " 'perverts': 3,\n",
       " 'loft': 9,\n",
       " 'goren': 1,\n",
       " 'ravings': 2,\n",
       " 'hemoglobin': 5,\n",
       " 'bide': 4,\n",
       " 'tch': 19,\n",
       " 'sibling': 1,\n",
       " 'lassen': 1,\n",
       " 'delinquent': 5,\n",
       " 'blackish': 1,\n",
       " 'negotiations': 14,\n",
       " 'unborn': 4,\n",
       " 'reasonless': 1,\n",
       " 'lettering': 3,\n",
       " 'zucchini': 1,\n",
       " 'marshmellows': 1,\n",
       " 'assassinate': 5,\n",
       " 'splashing': 6,\n",
       " 'boning': 4,\n",
       " 'bunsen': 1,\n",
       " 'wall': 235,\n",
       " 'sauvignon': 2,\n",
       " 'ignorance': 25,\n",
       " 'ottomans': 1,\n",
       " 'footloose': 1,\n",
       " 'frontier': 11,\n",
       " 'orderly': 12,\n",
       " 'skill': 33,\n",
       " 'virtually': 15,\n",
       " 'enzymes': 2,\n",
       " 'kidney': 12,\n",
       " 'spirits': 47,\n",
       " 'schimmelpenninck': 1,\n",
       " 'yous': 4,\n",
       " 'shmendrick': 1,\n",
       " 'payphone': 5,\n",
       " 'thinners': 1,\n",
       " 'spiteful': 4,\n",
       " 'lt': 43,\n",
       " 'egad': 1,\n",
       " \"democrats'\": 1,\n",
       " 'lambston': 1,\n",
       " 'bari': 4,\n",
       " 'preference': 9,\n",
       " 'abouta': 1,\n",
       " 'minks': 6,\n",
       " 'sleepwalks': 2,\n",
       " \"o'connor\": 6,\n",
       " 'suck': 102,\n",
       " 'discuss': 158,\n",
       " 'pancake': 3,\n",
       " 'exotic': 15,\n",
       " 'slumber': 4,\n",
       " 'results': 46,\n",
       " 'takagi': 4,\n",
       " 'poppa': 6,\n",
       " 'hochstetler': 2,\n",
       " 'hulmes': 1,\n",
       " 'angus': 2,\n",
       " 'nay': 23,\n",
       " 'slid': 8,\n",
       " 'dolores': 35,\n",
       " 'rosatos': 2,\n",
       " 'monogamous': 2,\n",
       " 'jerses': 5,\n",
       " 'scoots': 1,\n",
       " 'caraft': 1,\n",
       " 'bricks': 10,\n",
       " 'mcmurphy': 46,\n",
       " 'shorty': 19,\n",
       " 'dickie': 76,\n",
       " 'brendan': 1,\n",
       " 'padilla': 1,\n",
       " 'sheiks': 1,\n",
       " 'gizzard': 5,\n",
       " 'moses': 15,\n",
       " \"'upper\": 1,\n",
       " 'raining': 17,\n",
       " 'yeats': 1,\n",
       " 'fire': 655,\n",
       " 'warts': 3,\n",
       " 'cafes': 1,\n",
       " 'alvy': 53,\n",
       " 'tripped': 10,\n",
       " 'wringing': 1,\n",
       " 'claim': 76,\n",
       " 'classmates': 9,\n",
       " 'favours': 3,\n",
       " 'interlaced': 1,\n",
       " 'microchip': 3,\n",
       " 'hinterlands': 1,\n",
       " 'darius': 2,\n",
       " 'glassy': 1,\n",
       " 'filling': 30,\n",
       " 'uranium': 13,\n",
       " 'fal': 1,\n",
       " 'intellect': 19,\n",
       " 'vigor': 3,\n",
       " 'palmer': 32,\n",
       " 'fragment': 1,\n",
       " 'okaying': 1,\n",
       " 'weeds': 8,\n",
       " 'meurice': 12,\n",
       " \"how'd\": 351,\n",
       " 'njac': 1,\n",
       " 'fuzz': 1,\n",
       " \"'parasites\": 1,\n",
       " 'bitte': 1,\n",
       " 'raper': 3,\n",
       " 'slug': 16,\n",
       " 'incidentals': 3,\n",
       " 'prominence': 1,\n",
       " '50th': 1,\n",
       " 'styled': 2,\n",
       " 'titanus': 1,\n",
       " 'disgusting': 58,\n",
       " 'unmanned': 2,\n",
       " 'hypnotherapy': 1,\n",
       " 'honeywell': 2,\n",
       " 'hormone': 9,\n",
       " '1917': 2,\n",
       " 'claudia': 67,\n",
       " '14': 42,\n",
       " 'epileptic': 4,\n",
       " 'comancheros': 1,\n",
       " 'spills': 10,\n",
       " 'galen': 3,\n",
       " 'possession': 65,\n",
       " 'actresses': 12,\n",
       " 'catwomen': 3,\n",
       " 'repined': 1,\n",
       " \"y'ass\": 2,\n",
       " 'workin': 3,\n",
       " 'cottage': 10,\n",
       " 'birthmark': 3,\n",
       " 'quintet': 5,\n",
       " 'centaurus': 1,\n",
       " 'heathens': 3,\n",
       " 'lubricant': 1,\n",
       " 'beefs': 1,\n",
       " 'douse': 2,\n",
       " 'bullwhip': 1,\n",
       " 'why’s': 1,\n",
       " 'telepathic': 2,\n",
       " 'selectees': 1,\n",
       " 'bethesda': 2,\n",
       " 'showroom': 3,\n",
       " 'bossing': 1,\n",
       " 'sandals': 1,\n",
       " 'scrolls': 6,\n",
       " 'irregularities': 1,\n",
       " 'niagara': 11,\n",
       " 'oatmeal': 1,\n",
       " 'egelhoffer': 4,\n",
       " 'prowling': 2,\n",
       " 'zmuda': 1,\n",
       " 'showering': 2,\n",
       " 'quite': 781,\n",
       " 'bedroom': 113,\n",
       " 'simms': 9,\n",
       " 'tied': 89,\n",
       " 'sshheeiillaaa': 1,\n",
       " '!!!': 318,\n",
       " 'validity': 1,\n",
       " 'aigue': 1,\n",
       " 'hte': 1,\n",
       " 'hat—': 1,\n",
       " 'delhi': 9,\n",
       " 'suticases': 1,\n",
       " 'scrabble': 4,\n",
       " 'disbelieve': 2,\n",
       " 'grrrhmmnnnjkjmmmnn': 1,\n",
       " 'commuted': 1,\n",
       " 'amazed': 22,\n",
       " 'idolize': 1,\n",
       " 'wahoo': 4,\n",
       " 'reactionary': 3,\n",
       " 'loneliness': 11,\n",
       " '—do': 1,\n",
       " 'reminders': 2,\n",
       " 'obeah': 2,\n",
       " 'jerk': 115,\n",
       " 'vamos': 1,\n",
       " '257': 1,\n",
       " 'cabiria': 1,\n",
       " '21': 24,\n",
       " 'sisco': 6,\n",
       " 'analog': 1,\n",
       " 'shumann': 1,\n",
       " 'publicize': 3,\n",
       " 'potentiality': 1,\n",
       " 'obsessed': 41,\n",
       " 'thematically': 1,\n",
       " 'kee': 4,\n",
       " 'lov': 3,\n",
       " 'criers': 1,\n",
       " '112': 2,\n",
       " 'navi': 2,\n",
       " 'smut': 7,\n",
       " 'nygma': 5,\n",
       " 'surrogate': 4,\n",
       " 'smacks': 2,\n",
       " 'rachet': 1,\n",
       " 'robby': 1,\n",
       " 'satisfied': 76,\n",
       " 'joad': 7,\n",
       " 'cinematographers': 1,\n",
       " 'blueprints': 10,\n",
       " 'mindless': 16,\n",
       " 'i’ll': 30,\n",
       " 'please': 2560,\n",
       " 'jayne': 8,\n",
       " 'sugarballs': 1,\n",
       " 'paraplegic': 1,\n",
       " 'zephram': 5,\n",
       " 'fallbrooks': 1,\n",
       " 'chippendale': 1,\n",
       " 'viceroy': 5,\n",
       " 'transformed': 7,\n",
       " 'craig': 78,\n",
       " 'flier': 1,\n",
       " 'crows': 11,\n",
       " 'empathize': 3,\n",
       " 'nuevo': 1,\n",
       " 'junkies': 12,\n",
       " 'intolerance': 1,\n",
       " 'coveted': 1,\n",
       " 'chasten': 1,\n",
       " 'paged': 2,\n",
       " \"knock'em\": 1,\n",
       " 'doña': 1,\n",
       " 'dead': 2053,\n",
       " 'shutdown': 2,\n",
       " 'lassitude': 1,\n",
       " 'frosted': 1,\n",
       " 'linois': 1,\n",
       " 'funnier': 5,\n",
       " 'mohawk': 4,\n",
       " 'burping': 1,\n",
       " 'dollface': 4,\n",
       " 'basher': 2,\n",
       " 'klingon': 31,\n",
       " 'excepting': 2,\n",
       " 'trafficking’s': 1,\n",
       " 'winners': 11,\n",
       " 'response': 54,\n",
       " 'doggy': 4,\n",
       " 'cds': 10,\n",
       " 'gq': 1,\n",
       " 'unraveled': 1,\n",
       " 'tracked': 23,\n",
       " 'jinxes': 1,\n",
       " 'brooded': 1,\n",
       " 'styling': 1,\n",
       " 'estos': 1,\n",
       " 'blend': 17,\n",
       " \"flavors'\": 1,\n",
       " 'oaf': 2,\n",
       " 'camols': 1,\n",
       " 'garnie': 1,\n",
       " 'enrique': 16,\n",
       " 'mashed': 5,\n",
       " 'renderings': 1,\n",
       " \"she'll\": 347,\n",
       " 'shortchanged': 3,\n",
       " 'sar': 1,\n",
       " 'brained': 6,\n",
       " 'cookaboo': 1,\n",
       " 'poking': 17,\n",
       " 'fantasized': 3,\n",
       " 'roddy': 1,\n",
       " 'proponent': 1,\n",
       " 'arbor': 7,\n",
       " 'hoy': 1,\n",
       " \"'ball\": 1,\n",
       " 'accorded': 3,\n",
       " 'scanned': 6,\n",
       " 'scoring': 6,\n",
       " 'spun': 2,\n",
       " 'delbruck': 6,\n",
       " 'specs': 2,\n",
       " 'injected': 9,\n",
       " 'misdemeanor': 10,\n",
       " 'motherfuckers': 23,\n",
       " 'normandy': 4,\n",
       " 'tallow': 5,\n",
       " 'calloused': 1,\n",
       " 'flyer': 16,\n",
       " 'spouse': 4,\n",
       " 'choirs': 1,\n",
       " 'slap': 35,\n",
       " 'astronaut': 7,\n",
       " 'reverses': 2,\n",
       " 'retainer': 7,\n",
       " 'be—': 2,\n",
       " 'manzi': 2,\n",
       " 'cryptographer': 1,\n",
       " 'gomez': 6,\n",
       " 'longevity': 2,\n",
       " 'seaman': 2,\n",
       " 'neve': 1,\n",
       " 'remarry': 1,\n",
       " 'vertigo': 1,\n",
       " 'sociopath': 7,\n",
       " 'pants': 150,\n",
       " 'angling': 2,\n",
       " 'freeman': 6,\n",
       " 'rookie': 11,\n",
       " 'owwww': 5,\n",
       " 'brunelleschi': 1,\n",
       " 'watsa': 2,\n",
       " '8th': 7,\n",
       " 'tejas': 1,\n",
       " 'canton': 1,\n",
       " 'preposition': 2,\n",
       " 'embassy’s': 1,\n",
       " 'patriotic': 7,\n",
       " 'knob': 5,\n",
       " 'hurrrrts': 1,\n",
       " 'tugging': 1,\n",
       " 'landowners': 1,\n",
       " 'ruby': 44,\n",
       " 'erection': 8,\n",
       " 'mydick': 8,\n",
       " 'intruder': 10,\n",
       " 'du': 21,\n",
       " ...}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "name": "cornell_movie_dialogs_corpus.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
